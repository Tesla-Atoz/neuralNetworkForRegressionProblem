{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Artificial Neural Network for regression",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbb7fRy-eyr"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sNDnxE2-pwE"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxChR1Rk-umf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uBTqR3nacj0e",
        "outputId": "7aa9afc4-68e8-4b67-df44-a028bfde07dd"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG3FQEch-yuA"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4zq8Mza_D9O"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9CV13Co_HHM"
      },
      "source": [
        "# reading the dataset excel format.\n",
        "dataset = pd.read_excel('Folds5x2_pp.xlsx')\n",
        "# Extracting all the features \n",
        "X = dataset.iloc[:, :-1].values\n",
        "# Extracting the target variable\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCSq7Ajrrskf",
        "outputId": "3a8efb43-091a-45ed-eaf2-1ca86f8059cc"
      },
      "source": [
        "#taking a look at features from the dataset\r\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  14.96   41.76 1024.07   73.17]\n",
            " [  25.18   62.96 1020.04   59.08]\n",
            " [   5.11   39.4  1012.16   92.14]\n",
            " ...\n",
            " [  31.32   74.33 1012.92   36.48]\n",
            " [  24.48   69.45 1013.86   62.39]\n",
            " [  21.6    62.52 1017.23   67.87]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26W1E7iXrut9",
        "outputId": "67aeb798-f8e2-4436-fb27-349fd4231f31"
      },
      "source": [
        "#taking a look at target variable\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[463.26 444.37 488.56 ... 429.57 435.74 453.28]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC6omXel_Up0"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5edeb2r_agx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Splitting the dataset into train and test with  4:1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mSLlAT9_eyI"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsBULd_f_wLY"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Hd97Ls__Nz"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8Owjxa-6ynA"
      },
      "source": [
        "We can add any number of layers with any number of neurons or nodes. There is no fixed-procedure to get the values of them. It is the job of practitioner to experiment and get the best model. \r\n",
        "\r\n",
        "**Note:** Keras is included in Tensorflow 2.0 and higher versions.\r\n",
        "\r\n",
        "**PS** : *Neurons individually cannot do much but layers of them combined together possess super-power. Just like an ant cannot do much but colony of them can build an anthill.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iitAFJS_ABUn"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksO_Vv40AHix"
      },
      "source": [
        "# the first hidden layer with 6 neurons or nodes with rectifier activation function. 'relu' is the code for it.\r\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lb4kK_wAKbs"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2357OqEAQOQ"
      },
      "source": [
        "# adding another hidden layer with 6 neurons or nodes with rectifier activation function.\r\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwMOmKb3AdBY"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFATpzsUAkLL"
      },
      "source": [
        "#finally, adding the output layer with only one node.\r\n",
        "#Note here , I didnt provided activation kwarg coz for regression we donot need to \r\n",
        "#provide activation at the output coz output is continuous.(Basically thats what regression means)\r\n",
        "ann.add(tf.keras.layers.Dense(units=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq7e4fF6A1yy"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDeylAs2An25"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pesgbWlCAtB4"
      },
      "source": [
        "#compiling the neural network means configuring it with some defaults\r\n",
        "#to get optimal weights, optimization is necessary, I used 'adam' optimiser here.\r\n",
        "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjVuiybYOo7r"
      },
      "source": [
        "### Training the ANN model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_vV-tiiA5zn",
        "outputId": "31e889f9-99ab-4e6f-bfa9-4cb60e557546"
      },
      "source": [
        "#this part is favourite. Fitting the model with training set.\r\n",
        "# i did batch learing with batch_size =32, and epochs =100\r\n",
        "\r\n",
        "# we can play with those kwargs\r\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "240/240 [==============================] - 1s 980us/step - loss: 280667.1291\n",
            "Epoch 2/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 213304.8748\n",
            "Epoch 3/100\n",
            "240/240 [==============================] - 0s 992us/step - loss: 201079.9926\n",
            "Epoch 4/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 110795.2393\n",
            "Epoch 5/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 512.6503\n",
            "Epoch 6/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 429.1268\n",
            "Epoch 7/100\n",
            "240/240 [==============================] - 0s 996us/step - loss: 421.4852\n",
            "Epoch 8/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 403.6434\n",
            "Epoch 9/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 399.6967\n",
            "Epoch 10/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 384.6446\n",
            "Epoch 11/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 373.7554\n",
            "Epoch 12/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 369.1403\n",
            "Epoch 13/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 351.6928\n",
            "Epoch 14/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 329.1696\n",
            "Epoch 15/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 310.5357\n",
            "Epoch 16/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 292.3521\n",
            "Epoch 17/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 288.9992\n",
            "Epoch 18/100\n",
            "240/240 [==============================] - 0s 983us/step - loss: 261.8402\n",
            "Epoch 19/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 238.9680\n",
            "Epoch 20/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 224.5700\n",
            "Epoch 21/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 203.3284\n",
            "Epoch 22/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 188.9319\n",
            "Epoch 23/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 167.3817\n",
            "Epoch 24/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 156.6816\n",
            "Epoch 25/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 134.3539\n",
            "Epoch 26/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 123.9359\n",
            "Epoch 27/100\n",
            "240/240 [==============================] - 0s 970us/step - loss: 108.4634\n",
            "Epoch 28/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 95.7409\n",
            "Epoch 29/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 87.0716\n",
            "Epoch 30/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 74.2476\n",
            "Epoch 31/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 65.4152\n",
            "Epoch 32/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 58.1985\n",
            "Epoch 33/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 51.7039\n",
            "Epoch 34/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 45.7551\n",
            "Epoch 35/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 39.8092\n",
            "Epoch 36/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 35.6285\n",
            "Epoch 37/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 32.9960\n",
            "Epoch 38/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 30.7958\n",
            "Epoch 39/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 30.8002\n",
            "Epoch 40/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 29.0069\n",
            "Epoch 41/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.9279\n",
            "Epoch 42/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.0136\n",
            "Epoch 43/100\n",
            "240/240 [==============================] - 0s 998us/step - loss: 27.2011\n",
            "Epoch 44/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.2500\n",
            "Epoch 45/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.4604\n",
            "Epoch 46/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.5908\n",
            "Epoch 47/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.5673\n",
            "Epoch 48/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.5065\n",
            "Epoch 49/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8834\n",
            "Epoch 50/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.5043\n",
            "Epoch 51/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.4630\n",
            "Epoch 52/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.0671\n",
            "Epoch 53/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.4170\n",
            "Epoch 54/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.4970\n",
            "Epoch 55/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.2349\n",
            "Epoch 56/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.6009\n",
            "Epoch 57/100\n",
            "240/240 [==============================] - 0s 992us/step - loss: 26.2666\n",
            "Epoch 58/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.5715\n",
            "Epoch 59/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.3708\n",
            "Epoch 60/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.3712\n",
            "Epoch 61/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.1423\n",
            "Epoch 62/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.0338\n",
            "Epoch 63/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.3242\n",
            "Epoch 64/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.3320\n",
            "Epoch 65/100\n",
            "240/240 [==============================] - 0s 990us/step - loss: 26.5160\n",
            "Epoch 66/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.8174\n",
            "Epoch 67/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8307\n",
            "Epoch 68/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8361\n",
            "Epoch 69/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 28.2357\n",
            "Epoch 70/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.3140\n",
            "Epoch 71/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.2494\n",
            "Epoch 72/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.4131\n",
            "Epoch 73/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.5850\n",
            "Epoch 74/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8531\n",
            "Epoch 75/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.9550\n",
            "Epoch 76/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.5920\n",
            "Epoch 77/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.2983\n",
            "Epoch 78/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.9392\n",
            "Epoch 79/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.8181\n",
            "Epoch 80/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8281\n",
            "Epoch 81/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.7544\n",
            "Epoch 82/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.6724\n",
            "Epoch 83/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.3350\n",
            "Epoch 84/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8993\n",
            "Epoch 85/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.7418\n",
            "Epoch 86/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.3622\n",
            "Epoch 87/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.5969\n",
            "Epoch 88/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.6450\n",
            "Epoch 89/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.6141\n",
            "Epoch 90/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8913\n",
            "Epoch 91/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.3144\n",
            "Epoch 92/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.3174\n",
            "Epoch 93/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.9924\n",
            "Epoch 94/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.0577\n",
            "Epoch 95/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.4386\n",
            "Epoch 96/100\n",
            "240/240 [==============================] - 0s 995us/step - loss: 26.6305\n",
            "Epoch 97/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.8100\n",
            "Epoch 98/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.6536\n",
            "Epoch 99/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.8551\n",
            "Epoch 100/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 26.0785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb74a0ec780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H0zKKNEBLD5"
      },
      "source": [
        "### Predicting the results of the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA0yApEmBG1X",
        "outputId": "7ca0a0f8-3991-4120-93dc-aadac09c36ab"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "#just setting the precision of 2 for display\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[431.18 431.23]\n",
            " [462.23 460.01]\n",
            " [465.73 461.14]\n",
            " ...\n",
            " [472.96 473.26]\n",
            " [439.77 438.  ]\n",
            " [458.98 463.28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnr-DimG826g"
      },
      "source": [
        "**Evaluating our deep learning model.**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7jcpT9t1UP4",
        "outputId": "b025c074-9a54-46bc-9f9d-6a039ee3df5e"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,r2_score\r\n",
        "\r\n",
        "#Used regression score and mean square error as two metrics for evaluation\r\n",
        "# basically, r2_square close to 1 is a best model.\r\n",
        "print('Regression score function reuslt : ', r2_score(y_pred,y_test))\r\n",
        "print('mse : ', mean_squared_error(y_pred,y_test)  )\r\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regression score function reuslt :  0.911016088566643\n",
            "mse :  24.564055257436344\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}